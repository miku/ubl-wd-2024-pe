[https://groq.com/](https://groq.com/), [Think Fast: A Tensor Streaming
Processor (TSP) for Accelerating Deep Learning
Workloads](https://wow.groq.com/wp-content/uploads/2020/06/ISCA-TSP.pdf),
[one-pager](http://web.archive.org/web/20240219150015/https://wow.groq.com/wp-content/uploads/2023/11/Groq_LLMs_OnePager.pdf),
[1759372542530261154](https://twitter.com/JayScambler/status/1759372542530261154), [mini-ama](https://news.ycombinator.com/item?id=39429047), [groq-eng comment](https://www.reddit.com/r/LocalLLaMA/comments/1afm9af/comment/kog5l51/),
Mixtral 8x7B-32k, generated w/ 466.83 T/s

> Back-of-the-envelope calculation.

The following consists of about 450 words, generated end-to-end in 1.79s.
That's 21,720,600 words per day, or 86882 per day, or about 350 (250 pages)
books per day.

[Groq Says It Can Deploy 1 Million AI Inference Chips In Two Years](https://www.nextplatform.com/2023/11/27/groq-says-it-can-deploy-1-million-ai-inference-chips-in-two-years/) (2023), the demo uses about 500 chips.

> For its benchmarking, Groq linked together 576 of its GroqChips and ran
> inference against the LLaMA 2 model from Meta Platforms, scaling to 70
> billion parameters. The GroqRack has nine nodes, and normally these are eight
> nodes for compute and one as a redundant space, but for the benchmarks all
> nine nodes were used for compute to get 574 of these linked in three switched
> pods across those eight racks. (Each node has eight GroqCard adapters.

So, let's imagine: 500 * 350 books per day: that's 63,875,000 books per year.
How many books are [published per year by humans](https://en.wikipedia.org/wiki/Books_published_per_country_per_year)? Not that easy to answer, numbers [vary](https://isbndb.com/blog/how-many-books-are-in-the-world/), from 34M ISBN in the ISBN database to [129M ever published](https://booksearch.blogspot.com/2010/08/books-of-world-stand-up-and-be-counted.html), to

> UNESCO estimates that 2.2 million books are published every year. (2023)

Chips from that single, niche HW startup in 2025 could generate almost 30x the
"human" output per years (and there are other companies, build AI chips, like
[Intel](https://www.intel.com/content/www/us/en/products/docs/processors/core-ultra/ai-pc.html), [Nvidia](https://www.nvidia.com), [AMD](https://www.amd.com/en/products/software/rocm.html), ...).

----

> How could a reflective essay on the topic of computing, literature, automated
> writing start? Include some early, maybe obscure ideas that foreshadowed the
> automation of writing, thought and art.

Title: The Evolution of Computing and Its Impact on Literature and Automated
Writing: A Reflective Essay

Introduction:

The world of computing has experienced exponential growth over the past few
decades, transforming various aspects of our lives, including literature and
writing. The concept of automated writing, once a distant thought, has become a
reality, raising questions about the future of thought and art. This reflective
essay explores the early ideas that foreshadowed the automation of writing and
the potential implications of these advancements.

Early Ideas and Foreshadowing:

The roots of automated writing can be traced back to the early days of
computing and the works of pioneers like Ada Lovelace and Alan Turing.
Lovelace, in the 19th century, envisioned a time when machines could go beyond
mere calculation and create original music and art. Her prophetic notes on
Charles Babbage's Analytical Engine laid the groundwork for the concept of
automated creativity.

Similarly, Alan Turing, in his groundbreaking 1950 paper "Computing Machinery
and Intelligence," introduced the Turing Test, a measure of a machine's ability
to exhibit intelligent behavior equivalent to, or indistinguishable from, human
intelligence. This test, while initially focused on cognitive abilities, has
been adapted to evaluate the creativity and originality of machine-generated
content.

The Emergence of Computational Literary Analysis and Automated Writing:

The emergence of computational literary analysis in the late 20th century
marked a significant milestone in the automation of writing and literary
criticism. Researchers started using computational methods to analyze patterns,
themes, and structures in literary works, shedding new light on the
interpretation of texts.

In recent years, the development of sophisticated algorithms and machine
learning techniques has paved the way for the emergence of automated writing
tools. These tools can generate coherent and contextually relevant text,
challenging the notion of human exclusivity in the creative process.

Implications and Future Directions:

The rise of automated writing raises several questions about the future of
literature, thought, and art. Will machines eventually surpass human
creativity, or will they serve as tools that augment and expand human
capabilities? As automated writing becomes more sophisticated, how will it
reshape the way we approach education, critical thinking, and the
interpretation of texts?

In conclusion, the automation of writing and literary analysis represents a
fascinating intersection of computing, literature, and art. By reflecting on
the early ideas that foreshadowed these advancements, we can better understand
the potential implications and develop a nuanced perspective on the role of
automation in shaping the future of thought and creativity.
